{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c28aed0",
   "metadata": {},
   "source": [
    "# Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b60125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install SimpleITK torch torchio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea269197",
   "metadata": {},
   "source": [
    "## 1. Loading Images with SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eafa7088",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SimpleITK'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mSimpleITK\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msitk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load a 2D or 3D image (e.g., NIfTI, DICOM, etc.)\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SimpleITK'"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "# Load a 2D or 3D image (e.g., NIfTI, DICOM, etc.)\n",
    "image_path = '../data/sample_image.nii.gz'  # Update with your image path\n",
    "image = sitk.ReadImage(image_path)\n",
    "print('Image size:', image.GetSize())\n",
    "print('Image spacing:', image.GetSpacing())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e4076",
   "metadata": {},
   "source": [
    "## 2. Manipulating Imaging Arrays in NumPy and Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert SimpleITK image to NumPy array\n",
    "image_np = sitk.GetArrayFromImage(image)  # shape: (z, y, x) for 3D, (y, x) for 2D\n",
    "print('NumPy array shape:', image_np.shape)\n",
    "\n",
    "# Manipulate with NumPy (e.g., normalize)\n",
    "image_np_norm = (image_np - np.min(image_np)) / (np.max(image_np) - np.min(image_np))\n",
    "print('Normalized min/max:', image_np_norm.min(), image_np_norm.max())\n",
    "\n",
    "# Convert to Torch tensor\n",
    "image_tensor = torch.from_numpy(image_np_norm).float()\n",
    "print('Torch tensor shape:', image_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6200b",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation on 2D/3D Images using TorchIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829503ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "\n",
    "# TorchIO expects images in (C, Z, Y, X) or (C, Y, X) format\n",
    "if image_tensor.ndim == 3:\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # Add channel dimension\n",
    "elif image_tensor.ndim == 2:\n",
    "    image_tensor = image_tensor.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Create a TorchIO Subject\n",
    "subject = tio.Subject(\n",
    "    image=tio.ScalarImage(tensor=image_tensor)\n",
    ")\n",
    "\n",
    "# Define a data augmentation pipeline\n",
    "transform = tio.Compose([\n",
    "    tio.RandomFlip(axes=(0, 1)),\n",
    "    tio.RandomAffine(scales=(0.9, 1.1), degrees=10),\n",
    "    tio.RandomNoise(mean=0, std=0.1),\n",
    "    tio.RandomBiasField(coefficients=0.5)\n",
    "])\n",
    "\n",
    "# Apply augmentation\n",
    "augmented = transform(subject)\n",
    "aug_image = augmented.image.data\n",
    "print('Augmented image shape:', aug_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424c6dc",
   "metadata": {},
   "source": [
    "## 4. Visualize Original and Augmented Images (2D slice example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86472f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show a middle slice for 3D, or the image for 2D\n",
    "def show_slice(tensor, title):\n",
    "    arr = tensor.squeeze().cpu().numpy()\n",
    "    if arr.ndim == 3:\n",
    "        idx = arr.shape[0] // 2\n",
    "        arr = arr[idx]\n",
    "    plt.imshow(arr, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_slice(image_tensor, 'Original Image')\n",
    "show_slice(aug_image, 'Augmented Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472243d",
   "metadata": {},
   "source": [
    "## 5. NumPy to PyTorch Tensors: A Comparison Guide\n",
    "\n",
    "For those familiar with NumPy arrays, here are the key differences and similarities with PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92beb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. Creating arrays/tensors\n",
    "print(\"=== Creating Arrays/Tensors ===\")\n",
    "\n",
    "# NumPy\n",
    "np_array = np.array([1, 2, 3, 4, 5])\n",
    "np_zeros = np.zeros((3, 4))\n",
    "np_ones = np.ones((2, 3))\n",
    "np_random = np.random.rand(2, 3)\n",
    "\n",
    "# PyTorch (similar syntax)\n",
    "torch_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "torch_zeros = torch.zeros(3, 4)\n",
    "torch_ones = torch.ones(2, 3)\n",
    "torch_random = torch.rand(2, 3)\n",
    "\n",
    "print(\"NumPy array:\", np_array)\n",
    "print(\"PyTorch tensor:\", torch_tensor)\n",
    "print(\"Types:\", type(np_array), type(torch_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ecb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Converting between NumPy and PyTorch\n",
    "print(\"\\n=== Converting Between NumPy and PyTorch ===\")\n",
    "\n",
    "# NumPy to PyTorch\n",
    "np_to_torch = torch.from_numpy(np_array)\n",
    "print(\"NumPy to PyTorch:\", np_to_torch)\n",
    "\n",
    "# PyTorch to NumPy\n",
    "torch_to_np = torch_tensor.numpy()\n",
    "print(\"PyTorch to NumPy:\", torch_to_np)\n",
    "\n",
    "# Note: These share memory! Changes in one affect the other\n",
    "np_array[0] = 999\n",
    "print(\"After changing np_array[0]:\", np_to_torch)  # Also changed!\n",
    "\n",
    "# To avoid shared memory, use .clone() or .copy()\n",
    "safe_torch = torch.from_numpy(np_array.copy())\n",
    "safe_np = torch_tensor.clone().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Basic operations - very similar syntax!\n",
    "print(\"\\n=== Basic Operations ===\")\n",
    "\n",
    "np_a = np.array([[1, 2], [3, 4]])\n",
    "np_b = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "torch_a = torch.tensor([[1, 2], [3, 4]])\n",
    "torch_b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Addition\n",
    "print(\"NumPy addition:\", np_a + np_b)\n",
    "print(\"PyTorch addition:\", torch_a + torch_b)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(\"NumPy matmul:\", np.matmul(np_a, np_b))\n",
    "print(\"PyTorch matmul:\", torch.matmul(torch_a, torch_b))\n",
    "# or simply: torch_a @ torch_b\n",
    "\n",
    "# Reshaping\n",
    "print(\"NumPy reshape:\", np_a.reshape(-1))\n",
    "print(\"PyTorch reshape:\", torch_a.reshape(-1))\n",
    "# or: torch_a.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Key differences: Device and gradients\n",
    "print(\"\\n=== Key Differences ===\")\n",
    "\n",
    "# Device (CPU vs GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Available device:\", device)\n",
    "\n",
    "torch_cpu = torch.ones(2, 3)\n",
    "print(\"Tensor device:\", torch_cpu.device)\n",
    "\n",
    "# Move to GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    torch_gpu = torch_cpu.to('cuda')\n",
    "    print(\"GPU tensor device:\", torch_gpu.device)\n",
    "\n",
    "# Gradients (for automatic differentiation)\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()  # Compute gradients\n",
    "print(\"Gradient of x^2 at x=2:\", x.grad)  # Should be 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Common tensor operations for image processing\n",
    "print(\"\\n=== Image Processing Operations ===\")\n",
    "\n",
    "# Create a sample \"image\" tensor (batch_size, channels, height, width)\n",
    "image_tensor = torch.rand(1, 3, 64, 64)  # 1 RGB image, 64x64\n",
    "print(\"Image tensor shape:\", image_tensor.shape)\n",
    "\n",
    "# Indexing (similar to NumPy)\n",
    "red_channel = image_tensor[0, 0, :, :]  # First batch, red channel\n",
    "print(\"Red channel shape:\", red_channel.shape)\n",
    "\n",
    "# Permute dimensions (like np.transpose)\n",
    "# Change from NCHW to NHWC format\n",
    "image_hwc = image_tensor.permute(0, 2, 3, 1)\n",
    "print(\"NHWC format shape:\", image_hwc.shape)\n",
    "\n",
    "# Squeeze/unsqueeze (like np.squeeze/np.expand_dims)\n",
    "squeezed = image_tensor.squeeze(0)  # Remove batch dimension\n",
    "print(\"Squeezed shape:\", squeezed.shape)\n",
    "\n",
    "unsqueezed = squeezed.unsqueeze(0)  # Add batch dimension back\n",
    "print(\"Unsqueezed shape:\", unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Working with our medical image example\n",
    "print(\"\\n=== Medical Image Tensor Operations ===\")\n",
    "\n",
    "# Our image_tensor from earlier\n",
    "print(\"Original image tensor shape:\", image_tensor.shape)\n",
    "print(\"Data type:\", image_tensor.dtype)\n",
    "\n",
    "# Common operations you might do:\n",
    "\n",
    "# 1. Normalize (similar to NumPy)\n",
    "normalized = (image_tensor - image_tensor.mean()) / image_tensor.std()\n",
    "\n",
    "# 2. Add batch dimension if needed\n",
    "if image_tensor.dim() == 3:  # (C, H, W)\n",
    "    batched = image_tensor.unsqueeze(0)  # -> (1, C, H, W)\n",
    "    print(\"Added batch dimension:\", batched.shape)\n",
    "\n",
    "# 3. Convert data type\n",
    "float_tensor = image_tensor.float()  # Ensure float32\n",
    "print(\"Float tensor dtype:\", float_tensor.dtype)\n",
    "\n",
    "# 4. Clone for safety (like np.copy())\n",
    "image_copy = image_tensor.clone()\n",
    "\n",
    "# 5. Move to device for processing\n",
    "image_on_device = image_tensor.to(device)\n",
    "print(\"Image on device:\", image_on_device.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa612b",
   "metadata": {},
   "source": [
    "## Summary: NumPy vs PyTorch Tensors\n",
    "\n",
    "**Similarities:**\n",
    "- Very similar syntax for basic operations\n",
    "- Indexing, slicing, reshaping work almost identically\n",
    "- Mathematical operations are nearly the same\n",
    "\n",
    "**Key Differences:**\n",
    "- **Device support**: Tensors can live on GPU for faster computation\n",
    "- **Automatic differentiation**: Tensors can track gradients for deep learning\n",
    "- **Memory sharing**: Converting between NumPy and PyTorch shares memory by default\n",
    "- **Method names**: Some differences (e.g., `view()` vs `reshape()`, `permute()` vs `transpose()`)\n",
    "\n",
    "**For Medical Imaging:**\n",
    "- Use tensors when you need GPU acceleration\n",
    "- Use tensors for deep learning models\n",
    "- Convert to NumPy for visualization with matplotlib\n",
    "- Be aware of dimension ordering (NCHW vs NHWC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
